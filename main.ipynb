{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb7a3190dbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msksurv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, Input, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.compat.v2.summary as summary\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, Iterable, Sequence, Tuple, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bb7a3190dbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msksurv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": [
    "import sksurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (0.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Polsterl_tutorial.ipynb\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-43bf5a46b5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpatient_data_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpat_train_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPolsterl_tutorial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/import_ipynb.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ICC/Code/Polsterl_tutorial.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from patient_data_split import pat_train_test_split\n",
    "import Polsterl_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for development\n",
    "FILESTOLOAD = 100\n",
    "imdim_from_preprocessing = 299 # must match opt.ImageSize in image preprocessing configuration files\n",
    "imdim_for_network = 1024\n",
    "random_seed = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to csvs that connect patient id to slices and rfs label\n",
    "zero_info_path = '/Users/katyscott/Documents/ICC/Data/Labels/RFS_all_tumors_zero.csv'\n",
    "nan_info_path = '/Users/katyscott/Documents/ICC/Data/Labels/RFS_all_tumors_NaN.csv'\n",
    "\n",
    "zero_image_path = '/Users/katyscott/Documents/ICC/Data/Images/Tumors/' + str(imdim_from_preprocessing) + '/Zero/'\n",
    "nan_image_path = '/Users/katyscott/Documents/ICC/Data/Images/Tumors/' + str(imdim_from_preprocessing) + '/NaN/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in info for zero background images\n",
    "info = pd.read_csv(zero_info_path)\n",
    "image_fnames = np.asarray(info.iloc[:, 0])\n",
    "pat_num = np.asarray(info.iloc[:, 1])\n",
    "slice_num = np.asarray(info.iloc[:, 2])\n",
    "rfs_code = np.asarray(info.iloc[:, 3])\n",
    "rfs_time = np.asarray(info.iloc[:, 4])\n",
    "\n",
    "print(rfs_code.shape)\n",
    "print(rfs_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only loading in 100 number of files for development\n",
    "images = np.empty((1,imdim_for_network,imdim_for_network))\n",
    "file_count = 0\n",
    "for image_file in tqdm(image_fnames):\n",
    "    if file_count >= FILESTOLOAD:\n",
    "        break\n",
    "    else:\n",
    "        file_count += 1\n",
    "    #     print(\"Loading: \", image_file)\n",
    "        # Load in file as an numpy array\n",
    "        img = np.fromfile(zero_image_path + image_file)\n",
    "        # Reshape image from 1D to 2D array - need to not hardcode this, square root?\n",
    "        img_2D = np.reshape(img, (imdim_from_preprocessing,imdim_from_preprocessing))\n",
    "        # Scale image to this dimension, smooth image with Gaussian filter, pads with the reflection of the vector\n",
    "        # mirrored on the first and last values of the vector along each axis.\n",
    "        img_final = resize(img_2D, (imdim_for_network, imdim_for_network), anti_aliasing=True, mode='reflect')\n",
    "        # Not sure this next line is working, want an array with all the images as their own array in it\n",
    "        img_final_3D = np.reshape(img_final, (1,) + img_final.shape)\n",
    "        images = np.append(images, img_final_3D, axis=0)\n",
    "\n",
    "images = np.delete(images, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming images loaded in\n",
    "plt.imshow(images[1], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing split\n",
    "train_slice_indices, test_slice_indices = pat_train_test_split(pat_num[:FILESTOLOAD], rfs_code[:FILESTOLOAD], 0.7, random_seed)\n",
    "\n",
    "print(\"Train: \", np.array(train_slice_indices).shape)\n",
    "print(\"Test: \", np.array(test_slice_indices).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slices = images[train_slice_indices,:,:]#[:][:]\n",
    "train_slices = train_slices.squeeze() # Remove first dim of size 1\n",
    "\n",
    "train_labels = rfs_time[tuple(train_slice_indices)]\n",
    "print(\"Training set: \", train_slices.shape)\n",
    "print(\"Training labels: \", train_labels.shape)\n",
    "\n",
    "test_slices = images[test_slice_indices,:,:]\n",
    "test_slices = test_slices.squeeze() # Remove first dim of size 1\n",
    "\n",
    "test_labels = rfs_time[tuple(test_slice_indices)]\n",
    "print(\"Testing set: \", test_slices.shape)\n",
    "print(\"Testing labels: \", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_slices[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis for Deep Learning tutorial - Sebastian PÃ¶lsterl\n",
    "\n",
    "https://k-d-w.org/blog/2019/07/survival-analysis-for-deep-learning/\n",
    "\n",
    "Tensorflow 2 version of code\n",
    "\n",
    "https://nbviewer.jupyter.org/github/sebp/survival-cnn-estimator/blob/master/tutorial_tf2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(6, kernel_size=(5,5), activation='relu', name='conv_1'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Conv2D(16, (5,5), activation='relu', name='conv_2'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(120, activation='relu', name='dense_1'),\n",
    "        Dense(84, activation='relu', name='dense_2'),\n",
    "        Dense(1, activation='linear', name='dense_3')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = InputFunction(x_train, time_train, event_train, drop_last = True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepConvSurv \n",
    "(Zhu, Yao, & Huang, 2016)\n",
    "\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822579&casa_token=gVFzncUVfTgAAAAA:hGgPWCTzS2pUnsFG8xEZzZe7lAIupB_Z7SkKDnFJbilFmX1W6Ge5qCipPjiqCynL1lfSs64bVV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Input(shape=(imdim_for_network, imdim_for_network,1))\n",
    "\n",
    "network = Conv2D(filters=32, kernel_size=686, activation='relu', padding='valid')(img_in)\n",
    "network = MaxPool2D(pool_size=(2,2))(network)\n",
    "\n",
    "network = Conv2D(filters=32, kernel_size=88, activation='relu', padding='valid')(network)\n",
    "network = Conv2D(filters=32, kernel_size=43, activation='relu', padding='valid')(network)\n",
    "\n",
    "network = MaxPool2D(pool_size=(2,2))(network)\n",
    "\n",
    "network = Flatten()(network)\n",
    "network = Dense(32, activation='relu')(network)\n",
    "output = Dense(1, activation='exponential')(network)\n",
    "\n",
    "model = Model(inputs=img_in, outputs=output, name=\"deepconvsurv\")\n",
    "model.compile(\n",
    "        optimizer = Adam(),\n",
    "        loss='binary_crossentropy'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model: \" + model.name)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x = train_slices,\n",
    "                    y = train_labels,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_split = 0.15,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1 \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AUC metric vs. epoch plot\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model accuracy - ' + model.name)\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
