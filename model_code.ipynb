{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12742,
     "status": "ok",
     "timestamp": 1589637598598,
     "user": {
      "displayName": "Sebastian Pölsterl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GibzrfdaHThaPgjaoGC9Dfb7YXvuTd-tFLbzoO2Gb6WEwyKUsHIqQpwFQAnUAKIewfdDQm7LzvGMH1MzU0PGgU9JwdQ2_9F-5kiQH_DlB1ZaFKpkST5Oha3_n4379GpkI6TgsLF0WZU_7qikJ61kKM2ytdtJeEz5VVwoz3XdhEPaqbu57hGpX4JZ2aGKRbmVu9JQOU9u8Ym0_w4HOaywrK2s5F1H700i1y89hljff2afH6WLPCP2XSIW2-eK7Mkk1rWCYHvdKt2Q1F2cjNOVoPO3C_LDkAfl1U33HWfwTKRKrlf_fsw5BrBVeV65FDP2xxtFj47t1uNTni3fq9DSzMb30dX4v0k0zjKVI_PtxFOmm0VAhr1NYrNh5PgBfbgxjcCooOJbNg21wsosLvYazfQdbLZfeCNq79hK6ljJblvcDUdu9l8oV5WftCmYipe-pWi5_hd3RSeiJoHg1bRQctViY6KvOx8taENqNS6P3IY1zYVTlNYgews5dtAVR11ei3ofgB5vcBa-bfqgal4ZlJNcsCSwNzUaKMiQ3twG19ESCSnbgJTbLEb6hHeCyhGKoyRwFjCgvEixoU04BnxGH5SEh_qiXf4euMiEaALYK7SrH35KWoZTkW9wXShGv3CmgCdqyOloiG3QsusKVmB9PPCuLjw0A9ixzd3ktRotErkEH2N1_EAdQqti9CK9A3yirLJSyk7Vs6Uem3Jv1Jr21mHsFocw53FciKfwUXm-LydQGUQ9TvgiZepRPHJCypj3l-6Dg=s64",
      "userId": "18353690321324822306"
     },
     "user_tz": -120
    },
    "id": "kb7TWFXivEQc",
    "outputId": "17fa15cf-e4dd-441e-e667-31e39722f5e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-survival in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (0.15.0.post0)\n",
      "Requirement already satisfied: numexpr in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (2.7.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (1.1.3)\n",
      "Requirement already satisfied: scipy!=1.3.0,>=1.0 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn<0.25,>=0.24.0 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (0.24.1)\n",
      "Requirement already satisfied: numpy in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (1.19.2)\n",
      "Collecting osqp!=0.6.0,!=0.6.1\n",
      "  Using cached osqp-0.6.2.post0-cp38-cp38-macosx_10_9_x86_64.whl (164 kB)\n",
      "Requirement already satisfied: ecos in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (2.0.7.post1)\n",
      "Requirement already satisfied: joblib in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-survival) (0.17.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.25->scikit-survival) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.25->scikit-survival) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn<0.25,>=0.24.0->scikit-survival) (2.1.0)\n",
      "Requirement already satisfied: qdldl in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (0.1.5.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/katyscott/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.25->scikit-survival) (1.15.0)\n",
      "Installing collected packages: osqp\n",
      "Successfully installed osqp-0.6.2.post0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall --yes --quiet osqp\n",
    "!pip install scikit-survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1589637614533,
     "user": {
      "displayName": "Sebastian Pölsterl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GibzrfdaHThaPgjaoGC9Dfb7YXvuTd-tFLbzoO2Gb6WEwyKUsHIqQpwFQAnUAKIewfdDQm7LzvGMH1MzU0PGgU9JwdQ2_9F-5kiQH_DlB1ZaFKpkST5Oha3_n4379GpkI6TgsLF0WZU_7qikJ61kKM2ytdtJeEz5VVwoz3XdhEPaqbu57hGpX4JZ2aGKRbmVu9JQOU9u8Ym0_w4HOaywrK2s5F1H700i1y89hljff2afH6WLPCP2XSIW2-eK7Mkk1rWCYHvdKt2Q1F2cjNOVoPO3C_LDkAfl1U33HWfwTKRKrlf_fsw5BrBVeV65FDP2xxtFj47t1uNTni3fq9DSzMb30dX4v0k0zjKVI_PtxFOmm0VAhr1NYrNh5PgBfbgxjcCooOJbNg21wsosLvYazfQdbLZfeCNq79hK6ljJblvcDUdu9l8oV5WftCmYipe-pWi5_hd3RSeiJoHg1bRQctViY6KvOx8taENqNS6P3IY1zYVTlNYgews5dtAVR11ei3ofgB5vcBa-bfqgal4ZlJNcsCSwNzUaKMiQ3twG19ESCSnbgJTbLEb6hHeCyhGKoyRwFjCgvEixoU04BnxGH5SEh_qiXf4euMiEaALYK7SrH35KWoZTkW9wXShGv3CmgCdqyOloiG3QsusKVmB9PPCuLjw0A9ixzd3ktRotErkEH2N1_EAdQqti9CK9A3yirLJSyk7Vs6Uem3Jv1Jr21mHsFocw53FciKfwUXm-LydQGUQ9TvgiZepRPHJCypj3l-6Dg=s64",
      "userId": "18353690321324822306"
     },
     "user_tz": -120
    },
    "id": "ThvRyUyVvEQf",
    "outputId": "872381c5-d695-4bed-a4f8-bcc6d933aa34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Iterable, Sequence, Tuple, Optional, Union\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "print(\"Using Tensorflow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2888,)\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Constants for development\n",
    "FILESTOLOAD = 2888 # 2888 is all of them\n",
    "imdim_from_preprocessing = 256 # must match opt.ImageSize in image preprocessing configuration files\n",
    "imdim_for_network = 256\n",
    "random_seed = 16\n",
    "\n",
    "# Path to CSVs that connect patient id to slices and rfs label\n",
    "zero_info_path = \"/Users/katyscott/Documents/ICC/Data/Labels/\" + str(imdim_from_preprocessing) +\"/RFS_all_tumors_zero.csv\"\n",
    "zero_image_path = '/Users/katyscott/Documents/ICC/Data/Images/Tumors/' + str(imdim_from_preprocessing) + '/Zero/'\n",
    "\n",
    "# Reading in info for zero background images\n",
    "info = pd.read_csv(zero_info_path)\n",
    "image_fnames = np.asarray(info.iloc[:, 0])\n",
    "pat_num = np.asarray(info.iloc[:, 1])\n",
    "slice_num = np.asarray(info.iloc[:, 2])\n",
    "rfs_event = np.asarray(info.iloc[:, 3])\n",
    "rfs_time = np.asarray(info.iloc[:, 4])\n",
    "\n",
    "print(rfs_event.shape)\n",
    "print(rfs_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2888/2888 [23:12<00:00,  2.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1d04a4f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "\n",
    "images = np.empty((1,imdim_for_network,imdim_for_network))\n",
    "file_count = 0\n",
    "for image_file in tqdm(image_fnames):\n",
    "    if file_count >= FILESTOLOAD:\n",
    "        break\n",
    "    else:\n",
    "        file_count += 1\n",
    "    #     print(\"Loading: \", image_file)\n",
    "        # Load in file as an numpy array\n",
    "        img = np.fromfile(zero_image_path + image_file)\n",
    "        # Reshape image from 1D to 2D array - need to nothardcode this, square root?\n",
    "        img_2D = np.reshape(img, (imdim_from_preprocessing,imdim_from_preprocessing))\n",
    "        # Scale image to this dimension, smooth image with Gaussian filter, pads with the reflection of the vector\n",
    "        # mirrored on the first and last values of the vector along each axis.\n",
    "        img_final = resize(img_2D, (imdim_for_network, imdim_for_network), anti_aliasing=True, mode='reflect')\n",
    "        # Not sure this next line is working, want an array with all the images as their own array in it\n",
    "        img_final_3D = np.reshape(img_final, (1,) + img_final.shape)\n",
    "        images = np.append(images, img_final_3D, axis=0)\n",
    "\n",
    "images = np.delete(images, 0, axis=0)\n",
    "# Confirming images loaded in properly\n",
    "plt.imshow(images[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1e10abd00>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[11], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (2557, 256, 256)\n",
      "Training time labels:  (2557,)\n",
      "Training event labels:  (2557,)\n",
      "Testing set:  (686, 256, 256)\n",
      "Testing time labels:  (686,)\n",
      "Testing event labels:  (686,)\n"
     ]
    }
   ],
   "source": [
    "from patient_data_split import pat_train_test_split\n",
    "# Training and testing split\n",
    "split = 0.8\n",
    "train_slice_indices, test_slice_indices = pat_train_test_split(pat_num[:FILESTOLOAD], rfs_event[:FILESTOLOAD], split, random_seed)\n",
    "\n",
    "train_slices = images[train_slice_indices,:,:]#[:][:]\n",
    "train_slices = train_slices.squeeze() # Remove first dim of size 1\n",
    "\n",
    "train_time = rfs_time[train_slice_indices]\n",
    "train_event = rfs_event[train_slice_indices]\n",
    "print(\"Training set: \", train_slices.shape)\n",
    "print(\"Training time labels: \", train_time.shape)\n",
    "print(\"Training event labels: \", train_event.shape)\n",
    "\n",
    "test_slices = images[test_slice_indices,:,:]\n",
    "test_slices = test_slices.squeeze() # Remove first dim of size 1\n",
    "\n",
    "test_time = rfs_time[test_slice_indices]\n",
    "test_event = rfs_event[test_slice_indices]\n",
    "print(\"Testing set: \", test_slices.shape)\n",
    "print(\"Testing time labels: \", test_time.shape)\n",
    "print(\"Testing event labels: \", test_event.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 65536)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "# Convert rfs_event from numeric to boolean for use in sksurv\n",
    "b_rfs_event = np.array(rfs_event, dtype=bool)\n",
    "# Creating structured array for kaplan_meier_estimator\n",
    "rfs_type = np.dtype([('Status','bool'), ('Time', 'f')])\n",
    "rfs = np.empty(len(rfs_event),dtype=rfs_type)\n",
    "rfs['Status'] = b_rfs_event\n",
    "rfs['Time'] = rfs_time\n",
    "\n",
    "rfs_train = rfs[train_slice_indices]\n",
    "rfs_test = rfs[test_slice_indices]\n",
    "\n",
    "train_1D = np.reshape(train_slices, (train_slices.shape[0], train_slices.shape[1]*train_slices.shape[2]))\n",
    "test_1D = np.reshape(test_slices, (test_slices.shape[0], test_slices.shape[1]*test_slices.shape[2]))\n",
    "\n",
    "print(train_1D.shape)\n",
    "print(rfs_train.shape)\n",
    "estimator = CoxPHSurvivalAnalysis().fit(train_1D, rfs_train)\n",
    "\n",
    "risk_score = estimator.predict(train_1D)\n",
    "\n",
    "# score = (train_1D, rfs_train)\n",
    "\n",
    "# print(risk_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-HgnZlEvEQ5"
   },
   "outputs": [],
   "source": [
    "def _make_riskset(time: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute mask that represents each sample's risk set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : np.ndarray, shape=(n_samples,)\n",
    "        Observed event time sorted in descending order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    risk_set : np.ndarray, shape=(n_samples, n_samples)\n",
    "        Boolean matrix where the `i`-th row denotes the\n",
    "        risk set of the `i`-th instance, i.e. the indices `j`\n",
    "        for which the observer time `y_j >= y_i`.\n",
    "    \"\"\"\n",
    "    assert time.ndim == 1, \"expected 1D array\"\n",
    "\n",
    "    # sort in descending order\n",
    "    o = np.argsort(-time, kind=\"mergesort\")\n",
    "    \n",
    "    # Initialize risk set \n",
    "    n_samples = len(time)\n",
    "    risk_set = np.zeros((n_samples, n_samples), dtype=np.bool_)\n",
    "    \n",
    "    for i_org, i_sort in enumerate(o):\n",
    "        ti = time[i_sort]\n",
    "        k = i_org\n",
    "        while k < n_samples and ti == time[o[k]]:\n",
    "            k += 1\n",
    "        risk_set[i_sort, o[:k]] = True\n",
    "    return risk_set\n",
    "\n",
    "\n",
    "class InputFunction:\n",
    "    \"\"\"Callable input function that computes the risk set for each batch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : np.ndarray, shape=(n_samples, height, width)\n",
    "        Image data.\n",
    "    time : np.ndarray, shape=(n_samples,)\n",
    "        Observed time.\n",
    "    event : np.ndarray, shape=(n_samples,)\n",
    "        Event indicator.\n",
    "    batch_size : int, optional, default=64\n",
    "        Number of samples per batch.\n",
    "    drop_last : int, optional, default=False\n",
    "        Whether to drop the last incomplete batch.\n",
    "    shuffle : bool, optional, default=False\n",
    "        Whether to shuffle data.\n",
    "    seed : int, optional, default=89\n",
    "        Random number seed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 images: np.ndarray,\n",
    "                 time: np.ndarray,\n",
    "                 event: np.ndarray,\n",
    "                 batch_size: int = 64,\n",
    "                 drop_last: bool = False,\n",
    "                 shuffle: bool = False,\n",
    "                 seed: int = 89) -> None:\n",
    "        # If image is 3D, reduce dimension to 2D\n",
    "        if images.ndim == 3:\n",
    "            images = images[..., np.newaxis]\n",
    "        self.images = images\n",
    "        self.time = time\n",
    "        self.event = event\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Total number of samples.\"\"\"\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def steps_per_epoch(self) -> int:\n",
    "        \"\"\"Number of batches for one epoch.\"\"\"\n",
    "        return int(np.floor(self.size() / self.batch_size))\n",
    "\n",
    "    def _get_data_batch(self, index: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n",
    "        \"\"\"Compute risk set for samples in batch.\n",
    "        \n",
    "        Args:\n",
    "            index - indices for the batch\n",
    "\n",
    "        Returns:\n",
    "            images - numpy array of images in the batch\n",
    "            labels - dictionary of tuples (str, numpy array) with event, time, and riskset labels\n",
    "        \n",
    "        \"\"\"\n",
    "        time = self.time[index]\n",
    "        event = self.event[index]\n",
    "        images = self.images[index]\n",
    "\n",
    "        # Create dictionary of labels for the batch samples\n",
    "        labels = {\n",
    "            \"label_event\": event.astype(np.int32),\n",
    "            \"label_time\": time.astype(np.float32),\n",
    "            \"label_riskset\": _make_riskset(time)\n",
    "        }\n",
    "        return images, labels\n",
    "\n",
    "    def _iter_data(self) -> Iterable[Tuple[np.ndarray, Dict[str, np.ndarray]]]:\n",
    "        \"\"\"Generator that yields one batch at a time.\"\"\"\n",
    "        index = np.arange(self.size())\n",
    "        rnd = np.random.RandomState(self.seed)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rnd.shuffle(index)\n",
    "        for b in range(self.steps_per_epoch()):\n",
    "            start = b * self.batch_size\n",
    "            idx = index[start:(start + self.batch_size)]\n",
    "            yield self._get_data_batch(idx)\n",
    "\n",
    "        if not self.drop_last:\n",
    "            start = self.steps_per_epoch() * self.batch_size\n",
    "            idx = index[start:]\n",
    "            yield self._get_data_batch(idx)\n",
    "\n",
    "    def _get_shapes(self) -> Tuple[tf.TensorShape, Dict[str, tf.TensorShape]]:\n",
    "        \"\"\"Return shapes of data returned by `self._iter_data`.\n",
    "        \n",
    "        Returns:\n",
    "            images - tf.TensorShape, shape specification for images\n",
    "            labels - dictionary of (str, tf.TensorShape), shape specification for labels\n",
    "        \"\"\"\n",
    "        batch_size = self.batch_size if self.drop_last else None\n",
    "        h, w, c = self.images.shape[1:]\n",
    "        images = tf.TensorShape([batch_size, h, w, c])\n",
    "\n",
    "        labels = {k: tf.TensorShape((batch_size,))\n",
    "                  for k in (\"label_event\", \"label_time\")}\n",
    "        labels[\"label_riskset\"] = tf.TensorShape((batch_size, batch_size))\n",
    "        return images, labels\n",
    "\n",
    "    def _get_dtypes(self) -> Tuple[tf.DType, Dict[str, tf.DType]]:\n",
    "        \"\"\"Return dtypes of data returned by `self._iter_data`.\"\"\"\n",
    "        labels = {\"label_event\": tf.int32,\n",
    "                  \"label_time\": tf.float32,\n",
    "                  \"label_riskset\": tf.bool}\n",
    "        return tf.float32, labels\n",
    "\n",
    "    def _make_dataset(self) -> tf.data.Dataset:\n",
    "        \"\"\"Create dataset from generator.\"\"\"\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            self._iter_data,\n",
    "            self._get_dtypes(),\n",
    "            self._get_shapes()\n",
    "        )\n",
    "        return ds\n",
    "\n",
    "    def __call__(self) -> tf.data.Dataset:\n",
    "        return self._make_dataset()\n",
    "\n",
    "\n",
    "def safe_normalize(x: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Normalize risk scores to avoid exp underflowing.\n",
    "\n",
    "    Note that only risk scores relative to each other matter.\n",
    "    If minimum risk score is negative, we shift scores so minimum\n",
    "    is at zero.\n",
    "    \"\"\"\n",
    "    x_min = tf.reduce_min(x, axis=0)\n",
    "    c = tf.zeros_like(x_min)\n",
    "    norm = tf.where(x_min < 0, -x_min, c)\n",
    "    return x + norm\n",
    "\n",
    "\n",
    "def logsumexp_masked(risk_scores: tf.Tensor,\n",
    "                     mask: tf.Tensor,\n",
    "                     axis: int = 0,\n",
    "                     keepdims: Optional[bool] = None) -> tf.Tensor:\n",
    "    \"\"\"Compute logsumexp across `axis` for entries where `mask` is true.\n",
    "    \n",
    "    Args:\n",
    "        risk_scores - tf.Tensor of predicted outputs of CoxPH, must be 2D\n",
    "        mask - numpy array of boolean values with risk sets in rows, shape = (n_samples, n_samples)\n",
    "        axis - int indicating which axis to perform sum across, should be axis samples is on (?)\n",
    "        keepdims - bool, wheter to retain reduced dimensions in calculations\n",
    "    \n",
    "    Return:\n",
    "        output - tf.Tensor logsumexp for risk scores\n",
    "    \"\"\"\n",
    "    risk_scores.shape.assert_same_rank(mask.shape)\n",
    "\n",
    "    with tf.name_scope(\"logsumexp_masked\"):\n",
    "        mask_f = tf.cast(mask, risk_scores.dtype)\n",
    "        risk_scores_masked = tf.math.multiply(risk_scores, mask_f)\n",
    "        # for numerical stability, substract the maximum value\n",
    "        # before taking the exponential\n",
    "        amax = tf.reduce_max(risk_scores_masked, axis=axis, keepdims=True)\n",
    "        risk_scores_shift = risk_scores_masked - amax\n",
    "\n",
    "        exp_masked = tf.math.multiply(tf.exp(risk_scores_shift), mask_f)\n",
    "        exp_sum = tf.reduce_sum(exp_masked, axis=axis, keepdims=True)\n",
    "        output = amax + tf.math.log(exp_sum)\n",
    "        if not keepdims:\n",
    "            output = tf.squeeze(output, axis=axis)\n",
    "    return output\n",
    "\n",
    "\n",
    "class CoxPHLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Negative partial log-likelihood of Cox's proportional hazards model.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)            \n",
    "\n",
    "    def call(self,\n",
    "             y_true: Sequence[tf.Tensor],\n",
    "             y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Compute loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : list|tuple of tf.Tensor\n",
    "            The first element holds a binary vector where 1\n",
    "            indicates an event 0 censoring.\n",
    "            The second element holds the riskset, a\n",
    "            boolean matrix where the `i`-th row denotes the\n",
    "            risk set of the `i`-th instance, i.e. the indices `j`\n",
    "            for which the observer time `y_j >= y_i`.\n",
    "            Both must be rank 2 tensors.\n",
    "        y_pred : tf.Tensor\n",
    "            The predicted outputs. Must be a rank 2 tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : tf.Tensor\n",
    "            Loss for each instance in the batch.\n",
    "        \"\"\"\n",
    "        event, riskset = y_true\n",
    "        predictions = y_pred\n",
    "\n",
    "        # Input checking\n",
    "        pred_shape = predictions.shape\n",
    "        if pred_shape.ndims != 2:\n",
    "            raise ValueError(\"Rank mismatch: Rank of predictions (received %s) should \"\n",
    "                             \"be 2.\" % pred_shape.ndims)\n",
    "\n",
    "        if pred_shape[1] is None:\n",
    "            raise ValueError(\"Last dimension of predictions must be known.\")\n",
    "\n",
    "        if pred_shape[1] != 1:\n",
    "            raise ValueError(\"Dimension mismatch: Last dimension of predictions \"\n",
    "                             \"(received %s) must be 1.\" % pred_shape[1])\n",
    "\n",
    "        if event.shape.ndims != pred_shape.ndims:\n",
    "            raise ValueError(\"Rank mismatch: Rank of predictions (received %s) should \"\n",
    "                             \"equal rank of event (received %s)\" % (\n",
    "                pred_shape.ndims, event.shape.ndims))\n",
    "\n",
    "        if riskset.shape.ndims != 2:\n",
    "            raise ValueError(\"Rank mismatch: Rank of riskset (received %s) should \"\n",
    "                             \"be 2.\" % riskset.shape.ndims)\n",
    "\n",
    "        event = tf.cast(event, predictions.dtype)\n",
    "        # Normalize risk scores\n",
    "        predictions = safe_normalize(predictions)\n",
    "\n",
    "        # More input checking\n",
    "        with tf.name_scope(\"assertions\"):\n",
    "            assertions = (\n",
    "                tf.debugging.assert_less_equal(event, 1.),\n",
    "                tf.debugging.assert_greater_equal(event, 0.),\n",
    "                tf.debugging.assert_type(riskset, tf.bool)\n",
    "            )\n",
    "\n",
    "        # move batch dimension to the end so predictions get broadcast\n",
    "        # row-wise when multiplying by riskset\n",
    "        pred_t = tf.transpose(predictions)\n",
    "        # compute log of sum over risk set for each row\n",
    "        rr = logsumexp_masked(pred_t, riskset, axis=1, keepdims=True)\n",
    "        assert rr.shape.as_list() == predictions.shape.as_list()\n",
    "\n",
    "        losses = tf.math.multiply(event, rr - predictions)\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1232,
     "status": "error",
     "timestamp": 1589637629266,
     "user": {
      "displayName": "Sebastian Pölsterl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GibzrfdaHThaPgjaoGC9Dfb7YXvuTd-tFLbzoO2Gb6WEwyKUsHIqQpwFQAnUAKIewfdDQm7LzvGMH1MzU0PGgU9JwdQ2_9F-5kiQH_DlB1ZaFKpkST5Oha3_n4379GpkI6TgsLF0WZU_7qikJ61kKM2ytdtJeEz5VVwoz3XdhEPaqbu57hGpX4JZ2aGKRbmVu9JQOU9u8Ym0_w4HOaywrK2s5F1H700i1y89hljff2afH6WLPCP2XSIW2-eK7Mkk1rWCYHvdKt2Q1F2cjNOVoPO3C_LDkAfl1U33HWfwTKRKrlf_fsw5BrBVeV65FDP2xxtFj47t1uNTni3fq9DSzMb30dX4v0k0zjKVI_PtxFOmm0VAhr1NYrNh5PgBfbgxjcCooOJbNg21wsosLvYazfQdbLZfeCNq79hK6ljJblvcDUdu9l8oV5WftCmYipe-pWi5_hd3RSeiJoHg1bRQctViY6KvOx8taENqNS6P3IY1zYVTlNYgews5dtAVR11ei3ofgB5vcBa-bfqgal4ZlJNcsCSwNzUaKMiQ3twG19ESCSnbgJTbLEb6hHeCyhGKoyRwFjCgvEixoU04BnxGH5SEh_qiXf4euMiEaALYK7SrH35KWoZTkW9wXShGv3CmgCdqyOloiG3QsusKVmB9PPCuLjw0A9ixzd3ktRotErkEH2N1_EAdQqti9CK9A3yirLJSyk7Vs6Uem3Jv1Jr21mHsFocw53FciKfwUXm-LydQGUQ9TvgiZepRPHJCypj3l-6Dg=s64",
      "userId": "18353690321324822306"
     },
     "user_tz": -120
    },
    "id": "BUBru4MSvEQ-",
    "outputId": "c3ec2a25-6712-4395-c0b4-aebcdcfac4b4"
   },
   "outputs": [],
   "source": [
    "class CindexMetric:\n",
    "    \"\"\"Computes concordance index across one epoch.\"\"\"\n",
    "\n",
    "    def reset_states(self) -> None:\n",
    "        \"\"\"Clear the buffer of collected values.\"\"\"\n",
    "        self._data = {\n",
    "            \"label_time\": [],\n",
    "            \"label_event\": [],\n",
    "            \"prediction\": []\n",
    "        }\n",
    "\n",
    "    def update_state(self, y_true: Dict[str, tf.Tensor], y_pred: tf.Tensor) -> None:\n",
    "        \"\"\"Collect observed time, event indicator and predictions for a batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : dict\n",
    "            Must have two items:\n",
    "            `label_time`, a tensor containing observed time for one batch,\n",
    "            and `label_event`, a tensor containing event indicator for one batch.\n",
    "        y_pred : tf.Tensor\n",
    "            Tensor containing predicted risk score for one batch.\n",
    "        \"\"\"\n",
    "        self._data[\"label_time\"].append(y_true[\"label_time\"].numpy())\n",
    "        self._data[\"label_event\"].append(y_true[\"label_event\"].numpy())\n",
    "        self._data[\"prediction\"].append(tf.squeeze(y_pred).numpy())\n",
    "\n",
    "    def result(self) -> Dict[str, float]:\n",
    "        \"\"\"Computes the concordance index across collected values.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        metrics : dict\n",
    "            Computed metrics.\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        # Combine labels and predictions into one dictionary\n",
    "        for k, v in self._data.items():\n",
    "            data[k] = np.concatenate(v)\n",
    "\n",
    "        # Using c-index function sksurv\n",
    "        results = concordance_index_censored(\n",
    "            data[\"label_event\"] == 1,\n",
    "            data[\"label_time\"],\n",
    "            data[\"prediction\"])\n",
    "\n",
    "        result_data = {}\n",
    "        names = (\"cindex\", \"concordant\", \"discordant\", \"tied_risk\")\n",
    "        for k, v in zip(names, results):\n",
    "            result_data[k] = v\n",
    "\n",
    "        return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuSGDRpCvERA"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2.summary as summary\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "\n",
    "\n",
    "class TrainAndEvaluateModel:\n",
    "\n",
    "    def __init__(self, model, model_dir, train_dataset, eval_dataset,\n",
    "                 learning_rate, num_epochs):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.train_ds = train_dataset\n",
    "        self.val_ds = eval_dataset\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#         self.optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        self.loss_fn = CoxPHLoss()\n",
    "\n",
    "        self.train_loss_metric = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "        self.val_loss_metric = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "        self.val_cindex_metric = CindexMetric()\n",
    "\n",
    "    @tf.function\n",
    "    def train_one_step(self, x, y_event, y_riskset):\n",
    "        y_event = tf.expand_dims(y_event, axis=1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(x, training=True)\n",
    "\n",
    "            train_loss = self.loss_fn(y_true=[y_event, y_riskset], y_pred=logits)\n",
    "\n",
    "        with tf.name_scope(\"gradients\"):\n",
    "            grads = tape.gradient(train_loss, self.model.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        return train_loss, logits\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        # Store training checkpoint\n",
    "        ckpt = tf.train.Checkpoint(\n",
    "            step=tf.Variable(0, dtype=tf.int64),\n",
    "            optimizer=self.optimizer,\n",
    "            model=self.model)\n",
    "        ckpt_manager = tf.train.CheckpointManager(\n",
    "            ckpt, str(self.model_dir), max_to_keep=2)\n",
    "        # if this model was previously trained, start from last checkpoint\n",
    "        if ckpt_manager.latest_checkpoint:\n",
    "            ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "            print(f\"Latest checkpoint restored from {ckpt_manager.latest_checkpoint}.\")\n",
    "\n",
    "        train_summary_writer = summary.create_file_writer(\n",
    "            str(self.model_dir / \"train\"))\n",
    "        val_summary_writer = summary.create_file_writer(\n",
    "            str(self.model_dir / \"valid\"))\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            with train_summary_writer.as_default():\n",
    "                self.train_one_epoch(ckpt.step)\n",
    "\n",
    "            # Run a validation loop at the end of each epoch.\n",
    "            with val_summary_writer.as_default():\n",
    "                self.evaluate(ckpt.step)\n",
    "\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(f\"Saved checkpoint for step {ckpt.step.numpy()}: {save_path}\")\n",
    "\n",
    "    def train_one_epoch(self, step_counter):\n",
    "        for x, y in self.train_ds:\n",
    "            train_loss, logits = self.train_one_step(\n",
    "                x, y[\"label_event\"], y[\"label_riskset\"])\n",
    "\n",
    "            step = int(step_counter)\n",
    "            if step == 0:\n",
    "                # see https://stackoverflow.com/questions/58843269/display-graph-using-tensorflow-v2-0-in-tensorboard\n",
    "                func = self.train_one_step.get_concrete_function(\n",
    "                    x, y[\"label_event\"], y[\"label_riskset\"])\n",
    "                summary_ops_v2.graph(func.graph, step=0)\n",
    "\n",
    "            # Update training metric.\n",
    "            self.train_loss_metric.update_state(train_loss)\n",
    "\n",
    "            # Log every 200 batches.\n",
    "            if step % 200 == 0:\n",
    "                # Display metrics\n",
    "                mean_loss = self.train_loss_metric.result()\n",
    "                print(f\"step {step}: mean loss = {mean_loss:.4f}\")\n",
    "                # save summaries\n",
    "                summary.scalar(\"loss\", mean_loss, step=step_counter)\n",
    "                # Reset training metrics\n",
    "                self.train_loss_metric.reset_states()\n",
    "\n",
    "            step_counter.assign_add(1)\n",
    "\n",
    "    @tf.function\n",
    "    def evaluate_one_step(self, x, y_event, y_riskset):\n",
    "        y_event = tf.expand_dims(y_event, axis=1)\n",
    "        val_logits = self.model(x, training=False)\n",
    "        val_loss = self.loss_fn(y_true=[y_event, y_riskset], y_pred=val_logits)\n",
    "        return val_loss, val_logits\n",
    "\n",
    "    def evaluate(self, step_counter):\n",
    "        self.val_cindex_metric.reset_states()\n",
    "        \n",
    "        for x_val, y_val in self.val_ds:\n",
    "            val_loss, val_logits = self.evaluate_one_step(\n",
    "                x_val, y_val[\"label_event\"], y_val[\"label_riskset\"])\n",
    "\n",
    "            # Update val metrics\n",
    "            self.val_loss_metric.update_state(val_loss)\n",
    "            self.val_cindex_metric.update_state(y_val, val_logits)\n",
    "\n",
    "        val_loss = self.val_loss_metric.result()\n",
    "        summary.scalar(\"loss\",\n",
    "                       val_loss,\n",
    "                       step=step_counter)\n",
    "        self.val_loss_metric.reset_states()\n",
    "        \n",
    "        val_cindex = self.val_cindex_metric.result()\n",
    "        for key, value in val_cindex.items():\n",
    "            summary.scalar(key, value, step=step_counter)\n",
    "\n",
    "        print(f\"Validation: loss = {val_loss:.4f}, cindex = {val_cindex['cindex']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG2EK2s5vERD"
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', name='conv_1'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     tf.keras.layers.Conv2D(16, (5, 5), activation='relu', name='conv_2'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(120, activation='relu', name='dense_1'),\n",
    "#     tf.keras.layers.Dense(84, activation='relu', name='dense_2'),\n",
    "#     tf.keras.layers.Dense(1, activation='linear', name='dense_3')\n",
    "# ])\n",
    "\n",
    "# icc_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "#                   drop_last=True,\n",
    "#                   shuffle=True)\n",
    "\n",
    "# icc_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "# icc_trainer = TrainAndEvaluateModel(\n",
    "#     model=icc_model,\n",
    "#     model_dir=Path(\"ckpts-icc-cnn\"),\n",
    "#     train_dataset=icc_train_fn(),\n",
    "#     eval_dataset=icc_eval_fn(),\n",
    "#     learning_rate=0.0003,\n",
    "#     num_epochs=100,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training set: \", x_train.shape)\n",
    "# print(\"Training time labels:\", time_train.shape)\n",
    "# print(\"Training event labels:\", event_train.shape)\n",
    "\n",
    "# print(\"Testing set: \", x_test.shape)\n",
    "# print(\"Testing time labels: \", time_test.shape)\n",
    "# print(\"Testing event labels:\", event_test.shape)\n",
    "\n",
    "# plt.imshow(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hG2EK2s5vERD"
   },
   "outputs": [],
   "source": [
    "# Polsterl tutorial model\n",
    "icc_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), activation='relu', name='conv_1'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (5, 5), activation='relu', name='conv_2'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(84, activation='relu', name='dense_2'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='dense_3')\n",
    "])\n",
    "\n",
    "icc_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "                  drop_last=False,\n",
    "                  shuffle=True)\n",
    "\n",
    "icc_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "icc_trainer = TrainAndEvaluateModel(\n",
    "    model=icc_model,\n",
    "    model_dir=Path(\"ckpts-icc-cnn\"),\n",
    "    train_dataset=icc_train_fn(),\n",
    "    eval_dataset=icc_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing DeepConvSurv model\n",
    "dcs_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides = 3, activation='relu', name='conv_1'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides = 2, activation='relu', name='conv_2'),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides = 2, activation='relu', name='conv_3'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='dense_3')\n",
    "])\n",
    "\n",
    "dcs_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "                  batch_size=128,\n",
    "                  drop_last=False,\n",
    "                  shuffle=True)\n",
    "\n",
    "dcs_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "dcs_trainer = TrainAndEvaluateModel(\n",
    "    model=dcs_model,\n",
    "    model_dir=Path(\"ckpts-dcs-cnn-200\"),\n",
    "    train_dataset=dcs_train_fn(),\n",
    "    eval_dataset=dcs_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KT model \n",
    "# v1: Adding dropout layers between convolutional layers\n",
    "# v2: changed first dropout to 0.3 from 0.5, changed to selu activation\n",
    "# v3: train test split of 80-20\n",
    "# v4: removed first dropout\n",
    "# v6: first dropout 0.7, second 0.5\n",
    "# v7: changed optimizer in TrainandEvaluate to SGD, 100 epochs, increased learning rate, decreased dropout to 0.5\n",
    "kt_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(256,256,1)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides = 3, activation='selu', name='conv_1'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_1'),\n",
    "    tf.keras.layers.Dropout(0.7, seed=random_seed, name='drop_1'),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides = 2, activation='selu', name='conv_2'),\n",
    "    tf.keras.layers.Dropout(0.5, seed=random_seed, name='drop_2'),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides = 2, activation='selu', name='conv_3'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_2'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='selu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='dense_2')\n",
    "])\n",
    "\n",
    "kt_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "                  batch_size=64,\n",
    "                  drop_last=False,\n",
    "                  shuffle=True)\n",
    "\n",
    "kt_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "kt_trainer = TrainAndEvaluateModel(\n",
    "    model=kt_model,\n",
    "    model_dir=Path(\"ckpts-kt5-cnn-50\"),\n",
    "    train_dataset=kt_train_fn(),\n",
    "    eval_dataset=kt_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 84, 84, 32)        1600      \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)     (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "drop_1 (Dropout)             (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 19, 19, 32)        25632     \n",
      "_________________________________________________________________\n",
      "drop_2 (Dropout)             (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)     (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 52,929\n",
      "Trainable params: 52,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kt_model.compile(\n",
    "    optimizer='Adam', loss=CoxPHLoss()\n",
    ")\n",
    "kt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'visualkeras' has no attribute 'graph_view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-22280ebce2b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'visualkeras' has no attribute 'graph_view'"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "\n",
    "visualkeras.layered_view(kt_model).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing DeepConvSurv model\n",
    "dcs_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(7, 7), strides = 3, activation='relu', name='conv_1'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), strides = 2, activation='relu', name='conv_2'),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides = 2, activation='relu', name='conv_3'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='dense_3')\n",
    "])\n",
    "\n",
    "dcs_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "                  batch_size=128,\n",
    "                  drop_last=False,\n",
    "                  shuffle=True)\n",
    "\n",
    "dcs_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "dcs_trainer = TrainAndEvaluateModel(\n",
    "    model=dcs_model,\n",
    "    model_dir=Path(\"ckpts-dcs-cnn-200\"),\n",
    "    train_dataset=dcs_train_fn(),\n",
    "    eval_dataset=dcs_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: mean loss = 15.7132\n",
      "Validation: loss = 3.8263, cindex = 0.4640\n",
      "Validation: loss = 3.4315, cindex = 0.4615\n",
      "Validation: loss = 3.1637, cindex = 0.4452\n",
      "Validation: loss = 3.0712, cindex = 0.4386\n",
      "Validation: loss = 3.0458, cindex = 0.4487\n",
      "step 200: mean loss = 6.3152\n",
      "Validation: loss = 2.9942, cindex = 0.4509\n",
      "Validation: loss = 2.9678, cindex = 0.4540\n",
      "Validation: loss = 2.9552, cindex = 0.4624\n",
      "Validation: loss = 2.9410, cindex = 0.4668\n",
      "Validation: loss = 2.9327, cindex = 0.4703\n",
      "step 400: mean loss = 3.0472\n",
      "Validation: loss = 2.9264, cindex = 0.4691\n",
      "Validation: loss = 2.9169, cindex = 0.4755\n",
      "Validation: loss = 2.9128, cindex = 0.4765\n",
      "Validation: loss = 2.9087, cindex = 0.4771\n",
      "Validation: loss = 2.9059, cindex = 0.4830\n",
      "step 600: mean loss = 2.7759\n",
      "Validation: loss = 2.9036, cindex = 0.4809\n",
      "Validation: loss = 2.9011, cindex = 0.4764\n",
      "Validation: loss = 2.9008, cindex = 0.4830\n",
      "Validation: loss = 2.8985, cindex = 0.4866\n",
      "Validation: loss = 2.8994, cindex = 0.4838\n",
      "step 800: mean loss = 2.7057\n",
      "Validation: loss = 2.8980, cindex = 0.4771\n",
      "Validation: loss = 2.8980, cindex = 0.4776\n",
      "Validation: loss = 2.8979, cindex = 0.4805\n",
      "Validation: loss = 2.8976, cindex = 0.4821\n",
      "Validation: loss = 2.8977, cindex = 0.4813\n",
      "step 1000: mean loss = 2.6688\n",
      "Validation: loss = 2.8979, cindex = 0.4854\n",
      "Validation: loss = 2.8972, cindex = 0.4807\n",
      "Validation: loss = 2.8982, cindex = 0.4797\n",
      "Validation: loss = 2.8980, cindex = 0.4804\n",
      "Validation: loss = 2.8981, cindex = 0.4853\n",
      "step 1200: mean loss = 2.6566\n",
      "Validation: loss = 2.8973, cindex = 0.4873\n",
      "Validation: loss = 2.8985, cindex = 0.4894\n",
      "Validation: loss = 2.8992, cindex = 0.4903\n",
      "Validation: loss = 2.9020, cindex = 0.4903\n",
      "Validation: loss = 2.9004, cindex = 0.4936\n",
      "step 1400: mean loss = 2.6426\n",
      "Validation: loss = 2.8993, cindex = 0.4969\n",
      "Validation: loss = 2.9001, cindex = 0.5010\n",
      "Validation: loss = 2.9000, cindex = 0.4988\n",
      "Validation: loss = 2.8999, cindex = 0.4951\n",
      "Validation: loss = 2.9002, cindex = 0.4990\n",
      "step 1600: mean loss = 2.6378\n",
      "Validation: loss = 2.9013, cindex = 0.5034\n",
      "Validation: loss = 2.9005, cindex = 0.5056\n",
      "Validation: loss = 2.9030, cindex = 0.5059\n",
      "Validation: loss = 2.9024, cindex = 0.5070\n",
      "Validation: loss = 2.9030, cindex = 0.5068\n",
      "step 1800: mean loss = 2.6342\n",
      "Validation: loss = 2.9025, cindex = 0.5070\n",
      "Validation: loss = 2.9032, cindex = 0.5099\n",
      "Validation: loss = 2.9036, cindex = 0.5101\n",
      "Validation: loss = 2.9031, cindex = 0.5100\n",
      "Validation: loss = 2.9062, cindex = 0.5144\n",
      "Saved checkpoint for step 2000: ckpts-kt5-cnn-50/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "kt_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KT model 2\n",
    "ktv2_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(15, 15), strides = 3, activation='relu', name='conv_1'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.5, seed=random_seed, name='drop_1'),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(10, 10), strides = 2, activation='relu', name='conv_2'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.5, seed=random_seed, name='drop_2'),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), strides = 2, activation='relu', name='conv_3'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     tf.keras.layers.Dropout(0.5, seed=random_seed, name='drop_3'),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides = 2, activation='relu', name='conv_4'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     tf.keras.layers.Dropout(0.5, seed=random_seed, name='drop_4'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(32, activation='relu', name='dense_2'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', name='dense_3')\n",
    "])\n",
    "\n",
    "ktv2_train_fn = InputFunction(train_slices, train_time, train_event,\n",
    "                  batch_size=64,\n",
    "                  drop_last=False,\n",
    "                  shuffle=True)\n",
    "\n",
    "ktv2_eval_fn = InputFunction(test_slices, test_time, test_event)\n",
    "\n",
    "ktv2_trainer = TrainAndEvaluateModel(\n",
    "    model=kt_model,\n",
    "    model_dir=Path(\"ckpts-ktv2.1-cnn-100\"),\n",
    "    train_dataset=ktv2_train_fn(),\n",
    "    eval_dataset=ktv2_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: mean loss = 2.2749\n",
      "Validation: loss = 2.9867, cindex = 0.5390\n",
      "Validation: loss = 2.9913, cindex = 0.5411\n",
      "Validation: loss = 2.9823, cindex = 0.5347\n",
      "Validation: loss = 3.0204, cindex = 0.5494\n",
      "Validation: loss = 3.0183, cindex = 0.5474\n",
      "step 200: mean loss = 2.4917\n",
      "Validation: loss = 3.0433, cindex = 0.5481\n",
      "Validation: loss = 3.0302, cindex = 0.5516\n",
      "Validation: loss = 3.0601, cindex = 0.5515\n",
      "Validation: loss = 3.0609, cindex = 0.5488\n",
      "Validation: loss = 3.0038, cindex = 0.5570\n",
      "step 400: mean loss = 2.4953\n",
      "Validation: loss = 3.0081, cindex = 0.5505\n",
      "Validation: loss = 3.0081, cindex = 0.5420\n",
      "Validation: loss = 3.0286, cindex = 0.5507\n",
      "Validation: loss = 3.0198, cindex = 0.5494\n",
      "Validation: loss = 2.9794, cindex = 0.5303\n",
      "step 600: mean loss = 2.5323\n",
      "Validation: loss = 3.0284, cindex = 0.5438\n",
      "Validation: loss = 3.0086, cindex = 0.5470\n",
      "Validation: loss = 3.0189, cindex = 0.5460\n",
      "Validation: loss = 3.0464, cindex = 0.5542\n",
      "Validation: loss = 3.0410, cindex = 0.5551\n",
      "step 800: mean loss = 2.5180\n",
      "Validation: loss = 3.0759, cindex = 0.5494\n",
      "Validation: loss = 3.0496, cindex = 0.5538\n",
      "Validation: loss = 3.0657, cindex = 0.5561\n",
      "Validation: loss = 3.0409, cindex = 0.5486\n",
      "Validation: loss = 3.0514, cindex = 0.5429\n",
      "step 1000: mean loss = 2.5073\n",
      "Validation: loss = 3.0447, cindex = 0.5499\n",
      "Validation: loss = 3.0972, cindex = 0.5533\n",
      "Validation: loss = 3.0760, cindex = 0.5431\n",
      "Validation: loss = 3.0311, cindex = 0.5329\n",
      "Validation: loss = 3.0837, cindex = 0.5459\n",
      "step 1200: mean loss = 2.5061\n",
      "Validation: loss = 3.0754, cindex = 0.5494\n",
      "Validation: loss = 3.1200, cindex = 0.5493\n",
      "Validation: loss = 3.1110, cindex = 0.5436\n",
      "Validation: loss = 3.1034, cindex = 0.5412\n",
      "Validation: loss = 3.0988, cindex = 0.5471\n",
      "step 1400: mean loss = 2.4890\n",
      "Validation: loss = 3.1063, cindex = 0.5457\n",
      "Validation: loss = 3.1346, cindex = 0.5495\n",
      "Validation: loss = 3.1122, cindex = 0.5545\n",
      "Validation: loss = 3.1135, cindex = 0.5373\n",
      "Validation: loss = 3.1101, cindex = 0.5457\n",
      "step 1600: mean loss = 2.4839\n",
      "Validation: loss = 3.1612, cindex = 0.5500\n",
      "Validation: loss = 3.1294, cindex = 0.5460\n",
      "Validation: loss = 3.1582, cindex = 0.5493\n",
      "Validation: loss = 3.1720, cindex = 0.5499\n",
      "Validation: loss = 3.0628, cindex = 0.5343\n",
      "step 1800: mean loss = 2.4728\n",
      "Validation: loss = 3.1119, cindex = 0.5381\n",
      "Validation: loss = 3.0954, cindex = 0.5375\n",
      "Validation: loss = 3.1338, cindex = 0.5409\n",
      "Validation: loss = 3.1371, cindex = 0.5496\n",
      "Validation: loss = 3.1727, cindex = 0.5398\n",
      "step 2000: mean loss = 2.4667\n",
      "Validation: loss = 3.1208, cindex = 0.5370\n",
      "Validation: loss = 3.1670, cindex = 0.5390\n",
      "Validation: loss = 3.1956, cindex = 0.5364\n",
      "Validation: loss = 3.1954, cindex = 0.5385\n",
      "Validation: loss = 3.1882, cindex = 0.5388\n",
      "step 2200: mean loss = 2.4578\n",
      "Validation: loss = 3.1878, cindex = 0.5325\n",
      "Validation: loss = 3.1560, cindex = 0.5252\n",
      "Validation: loss = 3.1926, cindex = 0.5386\n",
      "Validation: loss = 3.2169, cindex = 0.5371\n",
      "Validation: loss = 3.1858, cindex = 0.5458\n",
      "step 2400: mean loss = 2.4485\n",
      "Validation: loss = 3.2292, cindex = 0.5479\n",
      "Validation: loss = 3.1940, cindex = 0.5476\n",
      "Validation: loss = 3.2115, cindex = 0.5347\n",
      "Validation: loss = 3.1888, cindex = 0.5338\n",
      "Validation: loss = 3.2874, cindex = 0.5409\n",
      "step 2600: mean loss = 2.4438\n",
      "Validation: loss = 3.2400, cindex = 0.5469\n",
      "Validation: loss = 3.2484, cindex = 0.5518\n",
      "Validation: loss = 3.2077, cindex = 0.5414\n",
      "Validation: loss = 3.2744, cindex = 0.5471\n",
      "Validation: loss = 3.2666, cindex = 0.5419\n",
      "step 2800: mean loss = 2.4393\n",
      "Validation: loss = 3.1800, cindex = 0.5324\n",
      "Validation: loss = 3.3018, cindex = 0.5472\n",
      "Validation: loss = 3.2266, cindex = 0.5430\n",
      "Validation: loss = 3.2332, cindex = 0.5417\n",
      "Validation: loss = 3.2760, cindex = 0.5468\n",
      "step 3000: mean loss = 2.4308\n",
      "Validation: loss = 3.2682, cindex = 0.5354\n",
      "Validation: loss = 3.2458, cindex = 0.5417\n",
      "Validation: loss = 3.3147, cindex = 0.5499\n",
      "Validation: loss = 3.3052, cindex = 0.5465\n",
      "Validation: loss = 3.2735, cindex = 0.5460\n",
      "step 3200: mean loss = 2.4278\n",
      "Validation: loss = 3.2181, cindex = 0.5445\n",
      "Validation: loss = 3.2584, cindex = 0.5365\n",
      "Validation: loss = 3.2388, cindex = 0.5416\n",
      "Validation: loss = 3.2325, cindex = 0.5448\n",
      "Validation: loss = 3.3081, cindex = 0.5475\n",
      "step 3400: mean loss = 2.4252\n",
      "Validation: loss = 3.3384, cindex = 0.5470\n",
      "Validation: loss = 3.2577, cindex = 0.5436\n",
      "Validation: loss = 3.2977, cindex = 0.5480\n",
      "Validation: loss = 3.2971, cindex = 0.5398\n",
      "Validation: loss = 3.2490, cindex = 0.5422\n",
      "step 3600: mean loss = 2.4137\n",
      "Validation: loss = 3.3159, cindex = 0.5416\n",
      "Validation: loss = 3.2710, cindex = 0.5413\n",
      "Validation: loss = 3.3021, cindex = 0.5410\n",
      "Validation: loss = 3.2876, cindex = 0.5434\n",
      "Validation: loss = 3.3662, cindex = 0.5426\n",
      "step 3800: mean loss = 2.4089\n",
      "Validation: loss = 3.3362, cindex = 0.5425\n",
      "Validation: loss = 3.2990, cindex = 0.5351\n",
      "Validation: loss = 3.2993, cindex = 0.5404\n",
      "Validation: loss = 3.3118, cindex = 0.5432\n",
      "Validation: loss = 3.3428, cindex = 0.5437\n",
      "Saved checkpoint for step 4000: ckpts-ktv2.1-cnn-100/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "ktv2_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying with Resnet \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Preprocess images for ResNet before creating InputFunction object\n",
    "res_train_slices = np.copy(train_slices)\n",
    "# copies the image three times so it's mimicing RGB\n",
    "res_train_slices =np.repeat(res_train_slices[..., np.newaxis], 3, -1)\n",
    "res_train_slices = preprocess_input(res_train_slices)\n",
    "\n",
    "res_test_slices = np.copy(test_slices)\n",
    "res_test_slices = np.repeat(res_test_slices[..., np.newaxis], 3, -1)\n",
    "res_test_slices = preprocess_input(res_test_slices)\n",
    "\n",
    "# Set up model\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "x = base_model.output\n",
    "x = Dense(32, activation='relu', name='dense_1')(x)\n",
    "output = Dense(1, activation='linear', name='dense_2')(x)\n",
    "\n",
    "res_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "# Create InputFunction object\n",
    "res_train_fn = InputFunction(res_train_slices, train_time, train_event,\n",
    "                  drop_last=True,\n",
    "                  shuffle=True)\n",
    "\n",
    "res_eval_fn = InputFunction(res_test_slices, test_time, test_event,\n",
    "                           drop_last=True,\n",
    "                           shuffle=True)\n",
    "\n",
    "# Set up Train and Eval model\n",
    "res_trainer = TrainAndEvaluateModel(\n",
    "    model=res_model,\n",
    "    model_dir=Path(\"ckpts-res50-100\"),\n",
    "    train_dataset=res_train_fn(),\n",
    "    eval_dataset=res_eval_fn(),\n",
    "    learning_rate=0.0003,\n",
    "    num_epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1f2d5ff10>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res_train_slices[2, :, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5Cwhd8gvERO"
   },
   "source": [
    "To obverse training, we can start TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wi1cPZKkvERT"
   },
   "source": [
    "Let the training begin…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not working yet\n",
    "# res_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiVyl83uvERP"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiVyl83uvERP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 5663), started 0:01:17 ago. (Use '!kill 5663' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6591e0da8f06e110\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6591e0da8f06e110\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TENSORBOARD_BINARY']='/Users/katyscott/Documents/ICC/venv/bin/tensorboard'\n",
    "\n",
    "%tensorboard --logdir ckpts-kt6-cnn-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored from ckpts-icc-cnn/ckpt-1.\n",
      "step 0: mean loss = 8.5225\n",
      "Validation: loss = 5.3744, cindex = 0.5323\n",
      "Validation: loss = 4.0676, cindex = 0.5669\n",
      "Validation: loss = 3.5734, cindex = 0.5585\n",
      "Validation: loss = 3.5479, cindex = 0.5361\n",
      "Validation: loss = 3.5841, cindex = 0.5481\n",
      "step 200: mean loss = 4.1782\n",
      "Validation: loss = 3.5742, cindex = 0.5479\n",
      "Validation: loss = 3.6786, cindex = 0.5514\n",
      "Validation: loss = 3.7784, cindex = 0.5581\n",
      "Validation: loss = 3.8849, cindex = 0.5584\n",
      "Validation: loss = 3.8933, cindex = 0.5575\n",
      "step 400: mean loss = 2.2825\n",
      "Validation: loss = 3.7537, cindex = 0.5675\n",
      "Validation: loss = 3.6877, cindex = 0.5669\n",
      "Validation: loss = 3.7728, cindex = 0.5516\n",
      "Validation: loss = 3.9350, cindex = 0.5713\n",
      "Validation: loss = 4.1185, cindex = 0.5787\n",
      "step 600: mean loss = 2.1696\n",
      "Validation: loss = 4.1863, cindex = 0.5740\n",
      "Validation: loss = 4.2590, cindex = 0.5753\n",
      "Validation: loss = 4.3108, cindex = 0.5908\n",
      "Validation: loss = 4.3108, cindex = 0.5691\n",
      "Validation: loss = 4.2579, cindex = 0.5831\n",
      "step 800: mean loss = 1.9774\n",
      "Validation: loss = 4.2463, cindex = 0.5876\n",
      "Validation: loss = 3.9681, cindex = 0.5759\n",
      "Validation: loss = 3.8580, cindex = 0.5565\n",
      "Validation: loss = 4.1268, cindex = 0.5705\n",
      "Validation: loss = 4.5275, cindex = 0.5775\n",
      "step 1000: mean loss = 1.9546\n",
      "Validation: loss = 4.6462, cindex = 0.5812\n",
      "Validation: loss = 4.7287, cindex = 0.5744\n",
      "Validation: loss = 5.1559, cindex = 0.5791\n",
      "Validation: loss = 5.1897, cindex = 0.5801\n",
      "Validation: loss = 5.1616, cindex = 0.5579\n",
      "step 1200: mean loss = 1.6844\n",
      "Validation: loss = 5.2445, cindex = 0.5567\n",
      "Validation: loss = 5.3179, cindex = 0.5497\n",
      "Validation: loss = 5.0669, cindex = 0.5623\n",
      "Validation: loss = 5.1112, cindex = 0.5626\n",
      "Validation: loss = 4.9479, cindex = 0.5747\n",
      "step 1400: mean loss = 1.7194\n",
      "Validation: loss = 5.2004, cindex = 0.5845\n",
      "Validation: loss = 5.1202, cindex = 0.5786\n",
      "Validation: loss = 4.6943, cindex = 0.5834\n",
      "Validation: loss = 4.9120, cindex = 0.5747\n",
      "Validation: loss = 5.2589, cindex = 0.5795\n",
      "Validation: loss = 5.6853, cindex = 0.5865\n",
      "step 1600: mean loss = 1.6314\n",
      "Validation: loss = 5.9097, cindex = 0.5972\n",
      "Validation: loss = 5.3060, cindex = 0.6160\n",
      "Validation: loss = 4.9492, cindex = 0.6046\n",
      "Validation: loss = 5.1824, cindex = 0.5816\n",
      "Validation: loss = 5.6309, cindex = 0.5762\n",
      "step 1800: mean loss = 1.5818\n",
      "Validation: loss = 5.9606, cindex = 0.5795\n",
      "Validation: loss = 6.2945, cindex = 0.5767\n",
      "Validation: loss = 6.3574, cindex = 0.5795\n",
      "Validation: loss = 5.5514, cindex = 0.5874\n",
      "Validation: loss = 5.8783, cindex = 0.5884\n",
      "step 2000: mean loss = 1.5091\n",
      "Validation: loss = 5.8864, cindex = 0.5993\n",
      "Validation: loss = 6.3184, cindex = 0.6019\n",
      "Validation: loss = 6.0994, cindex = 0.6038\n",
      "Validation: loss = 6.1960, cindex = 0.5964\n",
      "Validation: loss = 6.1320, cindex = 0.5973\n",
      "step 2200: mean loss = 1.3873\n",
      "Validation: loss = 6.1924, cindex = 0.5967\n",
      "Validation: loss = 6.7923, cindex = 0.5992\n",
      "Validation: loss = 7.0096, cindex = 0.5954\n",
      "Validation: loss = 6.7677, cindex = 0.6055\n",
      "Validation: loss = 6.8170, cindex = 0.6071\n",
      "step 2400: mean loss = 1.3588\n",
      "Validation: loss = 6.9190, cindex = 0.6043\n",
      "Validation: loss = 7.2202, cindex = 0.6091\n",
      "Validation: loss = 7.3698, cindex = 0.6039\n",
      "Validation: loss = 7.7851, cindex = 0.6066\n",
      "Validation: loss = 7.9121, cindex = 0.6001\n",
      "step 2600: mean loss = 1.2611\n",
      "Validation: loss = 7.9673, cindex = 0.6084\n",
      "Validation: loss = 6.9235, cindex = 0.6110\n",
      "Validation: loss = 6.8147, cindex = 0.6032\n",
      "Validation: loss = 7.3811, cindex = 0.5890\n",
      "Validation: loss = 7.7360, cindex = 0.5918\n",
      "step 2800: mean loss = 1.3194\n",
      "Validation: loss = 7.9359, cindex = 0.5882\n",
      "Validation: loss = 7.5135, cindex = 0.5848\n",
      "Validation: loss = 7.7946, cindex = 0.5909\n",
      "Validation: loss = 7.7509, cindex = 0.5998\n",
      "Validation: loss = 7.5236, cindex = 0.6027\n",
      "step 3000: mean loss = 1.2683\n",
      "Validation: loss = 6.8861, cindex = 0.5928\n",
      "Validation: loss = 7.0703, cindex = 0.5909\n",
      "Validation: loss = 7.9478, cindex = 0.6006\n",
      "Validation: loss = 8.7109, cindex = 0.6027\n",
      "Validation: loss = 8.2621, cindex = 0.5943\n",
      "Validation: loss = 8.0246, cindex = 0.6044\n",
      "step 3200: mean loss = 1.2219\n",
      "Validation: loss = 7.5478, cindex = 0.6145\n",
      "Validation: loss = 6.9718, cindex = 0.6194\n",
      "Validation: loss = 6.8086, cindex = 0.6132\n",
      "Validation: loss = 7.4755, cindex = 0.6125\n",
      "Validation: loss = 8.2167, cindex = 0.6098\n",
      "step 3400: mean loss = 1.2113\n",
      "Validation: loss = 9.1254, cindex = 0.6063\n",
      "Validation: loss = 9.0381, cindex = 0.5980\n",
      "Validation: loss = 8.3355, cindex = 0.6000\n",
      "Validation: loss = 8.2056, cindex = 0.6031\n",
      "Validation: loss = 8.5028, cindex = 0.5980\n",
      "step 3600: mean loss = 1.1356\n",
      "Validation: loss = 8.9746, cindex = 0.5974\n",
      "Validation: loss = 9.2848, cindex = 0.5954\n",
      "Validation: loss = 9.4170, cindex = 0.5949\n",
      "Validation: loss = 8.8848, cindex = 0.6014\n",
      "Validation: loss = 8.8289, cindex = 0.6023\n",
      "step 3800: mean loss = 1.0705\n",
      "Validation: loss = 9.2408, cindex = 0.6097\n",
      "Validation: loss = 9.3930, cindex = 0.6091\n",
      "Validation: loss = 8.9854, cindex = 0.6099\n",
      "Saved checkpoint for step 3900: ckpts-icc-cnn/ckpt-2\n"
     ]
    }
   ],
   "source": [
    "icc_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 92306,
     "status": "ok",
     "timestamp": 1589637998781,
     "user": {
      "displayName": "Sebastian Pölsterl",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GibzrfdaHThaPgjaoGC9Dfb7YXvuTd-tFLbzoO2Gb6WEwyKUsHIqQpwFQAnUAKIewfdDQm7LzvGMH1MzU0PGgU9JwdQ2_9F-5kiQH_DlB1ZaFKpkST5Oha3_n4379GpkI6TgsLF0WZU_7qikJ61kKM2ytdtJeEz5VVwoz3XdhEPaqbu57hGpX4JZ2aGKRbmVu9JQOU9u8Ym0_w4HOaywrK2s5F1H700i1y89hljff2afH6WLPCP2XSIW2-eK7Mkk1rWCYHvdKt2Q1F2cjNOVoPO3C_LDkAfl1U33HWfwTKRKrlf_fsw5BrBVeV65FDP2xxtFj47t1uNTni3fq9DSzMb30dX4v0k0zjKVI_PtxFOmm0VAhr1NYrNh5PgBfbgxjcCooOJbNg21wsosLvYazfQdbLZfeCNq79hK6ljJblvcDUdu9l8oV5WftCmYipe-pWi5_hd3RSeiJoHg1bRQctViY6KvOx8taENqNS6P3IY1zYVTlNYgews5dtAVR11ei3ofgB5vcBa-bfqgal4ZlJNcsCSwNzUaKMiQ3twG19ESCSnbgJTbLEb6hHeCyhGKoyRwFjCgvEixoU04BnxGH5SEh_qiXf4euMiEaALYK7SrH35KWoZTkW9wXShGv3CmgCdqyOloiG3QsusKVmB9PPCuLjw0A9ixzd3ktRotErkEH2N1_EAdQqti9CK9A3yirLJSyk7Vs6Uem3Jv1Jr21mHsFocw53FciKfwUXm-LydQGUQ9TvgiZepRPHJCypj3l-6Dg=s64",
      "userId": "18353690321324822306"
     },
     "user_tz": -120
    },
    "id": "SgS0SawuvERK",
    "outputId": "dc051681-3d59-4749-fa8f-4ed44393fddb"
   },
   "outputs": [],
   "source": [
    "# trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HMdg3qsKvERV"
   },
   "source": [
    "We can make a couple of observations:\n",
    "\n",
    "1. The final concordance index on the validation data is close to the optimal value we computed above using the actual underlying risk scores.\n",
    "2. The loss during training is quite volatile, which stems from the small batch size (64) and the varying number of uncensored samples that contribute to the loss in each batch. Increasing the batch size should yield smoother loss curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33q_ISFevERW"
   },
   "source": [
    "### Predicting Survival Functions\n",
    "\n",
    "For inference, things are much easier, we just pass a batch of images and record the predicted risk score. To estimate individual survival functions, we need to estimate the baseline hazard function $h_0$, which can be done analogous to the linear Cox PH model by using [Breslow's estimator](https://www.jstor.org/stable/1402659)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cI8ESLZcvERW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.linear_model.coxph import BreslowEstimator\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "\n",
    "    def __init__(self, model, model_dir):\n",
    "        self.model = model\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "    def predict(self, dataset):\n",
    "        ckpt = tf.train.Checkpoint(\n",
    "            step=tf.Variable(0, dtype=tf.int64),\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            model=self.model)\n",
    "        ckpt_manager = tf.train.CheckpointManager(\n",
    "            ckpt, str(self.model_dir), max_to_keep=2)\n",
    "\n",
    "        if ckpt_manager.latest_checkpoint:\n",
    "            ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "            print(f\"Latest checkpoint restored from {ckpt_manager.latest_checkpoint}.\")\n",
    "\n",
    "        risk_scores = []\n",
    "        for batch in dataset:\n",
    "            pred = self.model(batch, training=False)\n",
    "            risk_scores.append(pred.numpy())\n",
    "\n",
    "        return np.row_stack(risk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_fn = tf.data.Dataset.from_tensor_slices(x_train[..., np.newaxis]).batch(64)\n",
    "\n",
    "predictor = Predictor(model, trainer.model_dir)\n",
    "train_predictions = predictor.predict(train_pred_fn)\n",
    "\n",
    "breslow = BreslowEstimator().fit(train_predictions, event_train, time_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkhKNlgnvERZ"
   },
   "source": [
    "Once fitted, we can use Breslow's estimator to obtain estimated survival functions for images in the test data. We randomly draw three sample images for each digit and plot their predicted survival function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSdfNEJMvERa",
    "outputId": "16bf44f0-427b-4dd1-8a91-c22883e5e5c7"
   },
   "outputs": [],
   "source": [
    "sample = train_test_split(x_test, y_test, event_test, time_test,\n",
    "                          test_size=30, stratify=y_test, random_state=89)\n",
    "x_sample, y_sample, event_sample, time_sample = sample[1::2]\n",
    "\n",
    "sample_pred_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    x_sample[..., np.newaxis]).batch(64)\n",
    "sample_predictions = predictor.predict(sample_pred_ds)\n",
    "\n",
    "sample_surv_fn = breslow.get_survival_function(sample_predictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4.5))\n",
    "for surv_fn, class_label in zip(sample_surv_fn, y_sample):\n",
    "    risk_group = risk_score_assignment.loc[class_label, \"risk_group\"]\n",
    "    plt.step(surv_fn.x, surv_fn.y, where=\"post\",\n",
    "             color=f\"C{class_label}\", linestyle=styles[risk_group])\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Probability of survival $P(T > t)$\")\n",
    "plt.xlabel(\"Time $t$\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Wxzu2NGvERc"
   },
   "source": [
    "Solid lines correspond to images that belong to risk group 0 (with lowest risk), which the model was able to learn. Samples from the group with the highest risk are shown as dotted lines. Their predicted survival functions have the steepest descent, confirming that the model correctly identified different risk groups from images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dKl8PQotvERc"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We successfully built, trained, and evaluated a convolutional neural network for survival analysis on MNIST. While MNIST is obviously not a clinical dataset, the exact same approach can be used for clinical data. For instance, [Mobadersany et al.](https://www.pnas.org/content/115/13/E2970) used the same approach to predict overall survival of patients diagnosed with brain tumors from microscopic images, and [Zhu et al.](https://scholar.google.com/scholar?cluster=3381426605939025516) applied CNNs to predict survival of lung cancer patients from pathological images."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "new_ktenv",
   "language": "python",
   "name": "new_ktenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
